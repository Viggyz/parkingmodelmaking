{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lot_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jho4Ktjqhzol"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import PIL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81KeyBH6h6o2"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = 'AB.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  \n",
        "park_dir = os.path.join(os.path.dirname(\"park_photos\"), 'AB')\n",
        "data_dir = pathlib.Path(park_dir)\n",
        "\n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)\n",
        "\n",
        "free = list(data_dir.glob('busy/*'))\n",
        "PIL.Image.open(str(free[2]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IXt512XllQP"
      },
      "source": [
        "\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    park_dir,\n",
        "    target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size=(BATCH_SIZE),\n",
        "    subset='training',\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    park_dir,\n",
        "    target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size=(BATCH_SIZE),\n",
        "    subset='validation',\n",
        "    class_mode='binary'\n",
        ") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTl9jzNsktyg"
      },
      "source": [
        "image_batch, label_batch = next(val_generator)\n",
        "image_batch.shape, label_batch.shape\n",
        "\n",
        "class_names = sorted(train_generator.class_indices.keys())\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images in image_batch:\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image_batch[i])\n",
        "    plt.title(class_names[label_batch[i].astype(\"uint8\")])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68pZ0WuAI-ZQ"
      },
      "source": [
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('lot_labels.txt', 'w') as f:\n",
        "  f.write(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okMVnCloKIV6"
      },
      "source": [
        "IMG_SHAPE = (IMAGE_SIZE,IMAGE_SIZE,3)\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights=\"imagenet\")\n",
        "\n",
        "base_model.trainable=False\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmt6ICLCKo4C"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             base_model,\n",
        "                             tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                             tf.keras.layers.Dropout(0.2),\n",
        "                             tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mokUxq4kLrWA"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UST7DG6pLvkA"
      },
      "source": [
        "print('Number of trainable weights = {}'.format(len(model.trainable_weights)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vi_-hDNLzqN"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch = len(train_generator),\n",
        "                    epochs=15,\n",
        "                    validation_data = val_generator,\n",
        "                    validation_steps=len(val_generator)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9gNyiHINHO-"
      },
      "source": [
        "acc = history.history['binary_accuracy']\n",
        "val_acc = history.history['val_binary_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(acc, label='training_accuracy')\n",
        "plt.plot(val_acc, label='valication_accuracy')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(loss,label='Training Loss')\n",
        "plt.plot(val_loss,label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7uFhGaytYZi"
      },
      "source": [
        "#Working Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amh6QbA2na3G"
      },
      "source": [
        "image = tf.keras.preprocessing.image.load_img('20150703_0825_43.jpg',target_size=(224,224))\n",
        "input_arr = tf.keras.preprocessing.image.img_to_array(image,data_format='channels_last')\n",
        "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
        "predictions = model.predict(input_arr)\n",
        "print(predictions.item(0))\n",
        "\n",
        "class_labels = sorted(train_generator.class_indices.keys())\n",
        "print(\n",
        "    \"This image most likely belongs to {}\"\n",
        "    .format(class_labels[predictions.item(0)>0])\n",
        ")\n",
        "plt.imshow(image)\n",
        "plt.axis(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i610e9hgWGp2"
      },
      "source": [
        "# Fine Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOazYiMjOz0R"
      },
      "source": [
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trnV0HfpPvfk"
      },
      "source": [
        "base_model.trainable = True\n",
        "fine_tune_at = 85\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaZvA3LcAidI"
      },
      "source": [
        "model.evaluate(train_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUGpa5pqZPIx"
      },
      "source": [
        "model.evaluate(val_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L4oPM0_RXvw"
      },
      "source": [
        "acc = history.history['binary_accuracy']\n",
        "val_acc = history.history['val_binary_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9hs8oqUte2h"
      },
      "source": [
        "# Compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-fCDrpHtkfP"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('modified_mobilenet.tflite','wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hmNpelmvEyh"
      },
      "source": [
        "# A generator that provides a representative dataset\n",
        "def representative_data_gen():\n",
        "  dataset_list = tf.data.Dataset.list_files(park_dir + '/*/*')\n",
        "  for i in range(100):\n",
        "    image = next(iter(dataset_list))\n",
        "    image = tf.io.read_file(image)\n",
        "    image = tf.io.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    yield [image]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "# This enables quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# This sets the representative dataset for quantization\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# This ensures that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "# These set the input and output tensors to uint8 (added in r2.3)\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('mobilenet_v2_1.0_224_quant.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hn4pjTxvlLQ"
      },
      "source": [
        "batch_images, batch_labels = next(val_generator)\n",
        "\n",
        "logits = model(batch_images)\n",
        "prediction = np.where(logits>0, 1, 0)\n",
        "# print(prediction)\n",
        "print()\n",
        "\n",
        "keras_accuracy = tf.keras.metrics.Accuracy()\n",
        "keras_accuracy(prediction, batch_labels)\n",
        "\n",
        "print(\"Raw model accuracy: {:.3%}\".format(keras_accuracy.result()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONEPYYAhv3kK"
      },
      "source": [
        "def set_input_tensor(interpreter, input):\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  tensor_index = input_details['index']\n",
        "  input_tensor = interpreter.tensor(tensor_index)()[0]\n",
        "  # Inputs for the TFLite model must be uint8, so we quantize our input data.\n",
        "  # NOTE: This step is necessary only because we're receiving input data from\n",
        "  # ImageDataGenerator, which rescaled all image data to float [0,1]. When using\n",
        "  # bitmap inputs, they're already uint8 [0,255] so this can be replaced with:\n",
        "  #   input_tensor[:, :] = input\n",
        "  scale, zero_point = input_details['quantization']\n",
        "  input_tensor[:, :] = np.uint8(input / scale + zero_point)\n",
        "\n",
        "def classify_image(interpreter, input):\n",
        "  set_input_tensor(interpreter, input)\n",
        "  interpreter.invoke()\n",
        "  # tflite_results = tf_lite_interpreter.get_tensor(output_details['index'])\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "  # print(output_details)\n",
        "  output = interpreter.get_tensor(output_details['index'])\n",
        "  # print(output)\n",
        "  # Outputs from the TFLite model are uint8, so we dequantize the results:\n",
        "  scale, zero_point = output_details['quantization']\n",
        "  # print(scale,zero_point, output)\n",
        "  output = scale * (output - zero_point)\n",
        "  # print(output)\n",
        "  top_1 = np.where(output>11,0,1)\n",
        "  # top_1 = output.argmax()\n",
        "  return output\n",
        "\n",
        "interpreter = tf.lite.Interpreter('mobilenet_v2_1.0_224_quant.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Collect all inference predictions in a list\n",
        "batch_prediction = []\n",
        "batch_truth = batch_labels\n",
        "\n",
        "for i in range(len(batch_images)):\n",
        "  prediction = classify_image(interpreter, batch_images[i])\n",
        "  # print(prediction, batch_truth[i])\n",
        "  batch_prediction.append(prediction)\n",
        "\n",
        "print(np.array(batch_prediction).flatten())\n",
        "\n",
        "# print(batch_)\n",
        "\n",
        "# Compare all predictions to the ground truth\n",
        "tflite_accuracy = tf.keras.metrics.Accuracy()\n",
        "tflite_accuracy(np.array(batch_prediction).flatten(), batch_truth)\n",
        "print(\"Quant TF Lite accuracy: {:.3%}\".format(tflite_accuracy.result()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY_3fBQkwRp7"
      },
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "! sudo apt-get update\n",
        "\n",
        "! sudo apt-get install edgetpu-compiler\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj8LZRXXwS8d"
      },
      "source": [
        "! edgetpu_compiler mobilenet_v2_1.0_224_quant.tflite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knARvfVNwUuk"
      },
      "source": [
        "# Download the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypxnwEHCwXjv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b9af237e-602b-4802-ceca-a29b0df49777"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('mobilenet_v2_1.0_224_quant_edgetpu.tflite')\n",
        "files.download('lot_labels.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c16ac83d-0986-4fa7-bbfa-54b583fa24df\", \"mobilenet_v2_1.0_224_quant_edgetpu.tflite\", 2921088)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_22f7f89a-2af8-4b5e-9172-843662e06dfe\", \"lot_labels.txt\", 9)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}