{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAEbPzsbeHhp",
        "outputId": "391b8780-b1d3-4b93-fa95-c675f7d979db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwsfEmpPeLsc",
        "outputId": "7219574d-4b2c-48f5-ad7b-4e42cadc9fb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.7.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "import os\n",
        "import pathlib\n",
        "import PIL\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, ReLU, BatchNormalization, add,Softmax, AveragePooling2D, Dense, Input, GlobalAveragePooling2D, Activation, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXDz6h7eeNoT"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "train_zip = 'drive/MyDrive/Datasets/traindata.zip'\n",
        "val_zip = 'drive/MyDrive/Datasets/val_data.zip'\n",
        "test_zip = 'drive/MyDrive/Datasets/test_data.zip'\n",
        "\n",
        "with ZipFile(train_zip, 'r') as zip:\n",
        "  zip.extractall(\"train_photos\")\n",
        "\n",
        "with ZipFile(val_zip, 'r') as zip:\n",
        "  zip.extractall(\"val_photos\")\n",
        "\n",
        "with ZipFile(test_zip, 'r') as zip:\n",
        "  zip.extractall(\"test_photos\")\n",
        "  \n",
        "train_dir = os.path.join(\"./\", 'train_photos')\n",
        "val_dir = os.path.join(\"./\", 'val_photos')\n",
        "test_dir = os.path.join(\"./\", 'test_photos')\n",
        "\n",
        "# data_dir = pathlib.Path(train_dir)|\n",
        "# PIL.Image.open(str(free[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDxRWlzSeTul",
        "outputId": "59e27d2c-d859-41b3-bc0b-93127de6a96f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 94493 images belonging to 2 classes.\n",
            "Found 18647 images belonging to 2 classes.\n",
            "Found 31825 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 64 #64 cuz apparently needs to be 8? \n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    # width_shift_range=0.2,\n",
        "    # #make moe brightness generation!\n",
        "    # brightness_range=[0.2,1.0]\n",
        "    # height_shift_range=0.2,\n",
        "    # zoom_range=0.2,\n",
        "    # horizontal_flip=True,\n",
        "    # fill_mode=\"nearest\",\n",
        ")\n",
        "\n",
        "\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        ")\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size=(BATCH_SIZE),\n",
        "    # class_mode='binary'\n",
        "    class_mode='categorical',\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size=(BATCH_SIZE),\n",
        "    # class_mode='binary'\n",
        "    class_mode='categorical',\n",
        ") \n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size=(BATCH_SIZE),\n",
        "    # subset='validation',\n",
        "    # class_mode='binary'\n",
        "    class_mode='categorical'\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q45fWWoHtq5y"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9), #original 0.0005\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHjcvz0RvXry"
      },
      "outputs": [],
      "source": [
        "#V3 recommended training stats\n",
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, momentum=0.9),#,epsilon=0.002, rho=0.9), \n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz8R1mnKufYP"
      },
      "outputs": [],
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
        "\n",
        "rlrop = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience= 2, factor= 0.1, min_lr= 1e-4, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lgf9jGbuYEZ",
        "outputId": "8e934521-18b5-44db-e7b2-44c68da0fcc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "285/498 [================>.............] - ETA: 44:46 - loss: 0.2846 - accuracy: 0.9566"
          ]
        }
      ],
      "source": [
        "hist = model.fit(\n",
        "    test_generator,\n",
        "    epochs=3, \n",
        "    # steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stop, rlrop],)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5sjMaqk9Fvj",
        "outputId": "c6f27e76-2f88-4dfe-e398-4fa28122c1ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: mobnettpu/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  return generic_utils.serialize_keras_object(obj)\n"
          ]
        }
      ],
      "source": [
        "model.save(\"mobnettpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWGPuUod9IpM",
        "outputId": "4f70adb6-80aa-4337-c65b-28ab7f973e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: mobnettpu/ (stored 0%)\n",
            "  adding: mobnettpu/saved_model.pb (deflated 92%)\n",
            "  adding: mobnettpu/keras_metadata.pb (deflated 95%)\n",
            "  adding: mobnettpu/assets/ (stored 0%)\n",
            "  adding: mobnettpu/variables/ (stored 0%)\n",
            "  adding: mobnettpu/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: mobnettpu/variables/variables.index (deflated 81%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r mobnettpu.zip mobnettpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9_yC1e_-nIg",
        "outputId": "81c4cd28-10d3-46ee-fe30-a2c805ca0803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpjsbqe7sq/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpjsbqe7sq/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "def representative_data_gen():\n",
        "  dataset_list = tf.data.Dataset.list_files(test_dir + '/*/*')\n",
        "  for i in range(50):\n",
        "    image = next(iter(dataset_list))\n",
        "    image = tf.io.read_file(image)\n",
        "    image = tf.io.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    yield [image]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "# This enables quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# This sets the representative dataset for quantization\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# This ensures that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "# These set the input and output tensors to uint8 (added in r2.3)\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('mobnettputest.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwick_dSjcyq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h1fw4qPetza"
      },
      "outputs": [],
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "! sudo apt-get update\n",
        "\n",
        "! sudo apt-get install edgetpu-compiler\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H8S9MrEevKR",
        "outputId": "70e772cc-bea4-49c3-9111-0a3d482d3f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edge TPU Compiler version 16.0.384591198\n",
            "Started a compilation timeout timer of 180 seconds.\n",
            "\n",
            "Model compiled successfully in 1853 ms.\n",
            "\n",
            "Input model: mobnettputest.tflite\n",
            "Input size: 3.82MiB\n",
            "Output model: mobnettputest_edgetpu.tflite\n",
            "Output size: 4.12MiB\n",
            "On-chip memory used for caching model parameters: 3.86MiB\n",
            "On-chip memory remaining for caching model parameters: 3.83MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 139\n",
            "Operation log: mobnettputest_edgetpu.log\n",
            "See the operation log file for individual operation details.\n",
            "Compilation child process completed within timeout period.\n",
            "Compilation succeeded! \n"
          ]
        }
      ],
      "source": [
        "! edgetpu_compiler mobnettputest.tflite\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVN3rNHuvO0k"
      },
      "outputs": [],
      "source": [
        "def hard_swish(x):\n",
        "  x = x+3.0\n",
        "  return x * (ReLU(max_value=6)(x)/6.0)\n",
        "\n",
        "def return_activation(x,name):\n",
        "    x = Activation(hard_swish, name=name)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI018CAnf7Bx"
      },
      "outputs": [],
      "source": [
        "def expansion_block(x,t,filters,block_id):\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "    total_filters = t*filters\n",
        "    x = Conv2D(total_filters,1,padding='same',use_bias=False, name = prefix +'expand')(x)\n",
        "    x = BatchNormalization(name=prefix +'expand_bn')(x)\n",
        "    x = ReLU(6,name = prefix +'expand_relu')(x)\n",
        "    # x = return_activation(x, name = prefix +'expand_relu')\n",
        "    return x\n",
        "\n",
        "def depthwise_block(x,stride,block_id):\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "    x = DepthwiseConv2D(3,strides=(stride,stride),padding ='same', use_bias = False, name = prefix + 'depthwise_conv')(x)\n",
        "    x = BatchNormalization(name=prefix +'dw_bn')(x)\n",
        "    x = ReLU(6,name=prefix +'dw_relu')(x)\n",
        "    # x = return_activation(x, name = prefix +'dw_relu')\n",
        "    return x\n",
        "\n",
        "def expansion_block_HS(x,t,filters,block_id):\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "    total_filters = t*filters\n",
        "    x = Conv2D(total_filters,1,padding='same',use_bias=False, name = prefix +'expand')(x)\n",
        "    x = BatchNormalization(name=prefix +'expand_bn')(x)\n",
        "    # x = ReLU(6,name = prefix +'expand_relu')(x)\n",
        "    x = return_activation(x, name = prefix +'expand_relu')\n",
        "    return x\n",
        "\n",
        "def depthwise_block_HS(x,stride,block_id):\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "    x = DepthwiseConv2D(3,strides=(stride,stride),padding ='same', use_bias = False, name = prefix + 'depthwise_conv')(x)\n",
        "    x = BatchNormalization(name=prefix +'dw_bn')(x)\n",
        "    # x = ReLU(6,name=prefix +'dw_relu')(x)\n",
        "    x = return_activation(x, name = prefix +'dw_relu')\n",
        "    return x\n",
        "\n",
        "def projection_block(x,out_channels,block_id):\n",
        "    prefix = 'block_{}_'.format(block_id)\n",
        "    x = Conv2D(filters = out_channels,kernel_size = 1,padding='same',use_bias=False,name= prefix + 'compress')(x)\n",
        "    x = BatchNormalization(name=prefix +'compress_bn')(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aMqeGwZl5y9"
      },
      "outputs": [],
      "source": [
        "def Bottleneck(x,t,filters, out_channels,stride,block_id):\n",
        "    y = expansion_block(x,t,filters,block_id)\n",
        "    y = depthwise_block(y,stride,block_id)\n",
        "    y = projection_block(y, out_channels,block_id)\n",
        "    if y.shape[-1]==x.shape[-1]:\n",
        "        y = add([x,y])\n",
        "    return y\n",
        "\n",
        "def Bottleneck_HS(x,t,filters, out_channels,stride,block_id):\n",
        "    y = expansion_block_HS(x,t,filters,block_id)\n",
        "    y = depthwise_block_HS(y,stride,block_id)\n",
        "    y = projection_block(y, out_channels,block_id)\n",
        "    if y.shape[-1]==x.shape[-1]:\n",
        "        y = add([x,y])\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJBj12Rbl7e5"
      },
      "outputs": [],
      "source": [
        "def MobileNetV2(input_image = (224,224,3), n_classes=2):\n",
        "    input = Input(input_image)\n",
        "\n",
        "    x = Conv2D(32,kernel_size=3,strides=(2,2),padding = 'same', use_bias=False)(input)\n",
        "    x = BatchNormalization(name='conv1_bn')(x)\n",
        "    # x = ReLU(6, name = 'conv1_relu')(x)\n",
        "    x = return_activation(x, name='initial_hs')\n",
        "\n",
        "\n",
        "    # 17 Bottlenecks\n",
        "\n",
        "    x = depthwise_block(x,stride=1,block_id=1)\n",
        "    x = projection_block(x, out_channels=16,block_id=1)\n",
        "\n",
        "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 24, stride = 2,block_id = 2)\n",
        "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 24, stride = 1,block_id = 3)\n",
        "\n",
        "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 2,block_id = 4)\n",
        "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 5)\n",
        "    x = Bottleneck(x, t = 6, filters = x.shape[-1], out_channels = 32, stride = 1,block_id = 6)\n",
        "\n",
        "    x = Bottleneck_HS(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 2,block_id = 7)\n",
        "    x = Bottleneck_HS(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 8)\n",
        "    x = Bottleneck_HS(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 9)\n",
        "    x = Bottleneck_HS(x, t = 6, filters = x.shape[-1], out_channels = 64, stride = 1,block_id = 10)\n",
        "\n",
        "    x = Bottleneck_HS(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 11)\n",
        "    x = Bottleneck_HS(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 12)\n",
        "    x = Bottleneck_HS(x, t = 6, filters = x.shape[-1], out_channels = 96, stride = 1,block_id = 13)\n",
        "\n",
        "    x = Bottleneck_HS(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 2,block_id = 14)\n",
        "    x = Bottleneck_HS(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 15)\n",
        "    x = Bottleneck_HS(x, t = 6, filters = x.shape[-1], out_channels = 160, stride = 1,block_id = 16)\n",
        "\n",
        "    x = Bottleneck_HS(x, t = 6, filters = x.shape[-1], out_channels = 320, stride = 1,block_id = 17)\n",
        "\n",
        "    #1*1 conv\n",
        "    x = Conv2D(filters = 1280,kernel_size = 1,padding='same',use_bias=False, name = 'last_conv')(x)\n",
        "    x = BatchNormalization(name='last_bn')(x)\n",
        "    x = ReLU(6,name='last_relu')(x)\n",
        "\n",
        "    #AvgPool 7*7\n",
        "    x = GlobalAveragePooling2D(name='global_average_pool')(x)\n",
        "\n",
        "    output = Dense(n_classes,activation='softmax')(x)\n",
        "\n",
        "    model = Model(input, output)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A92p1-l0l9j8"
      },
      "outputs": [],
      "source": [
        "n_classes = 2\n",
        "input_shape = (224,224,3)\n",
        "\n",
        "model = MobileNetV2(input_shape,n_classes)\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2nCYuOZl_QL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "custommob.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}